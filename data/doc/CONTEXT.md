# ğŸ¯ Contexto del Proyecto LogsAnomaly

## ğŸ“‹ Resumen Ejecutivo

**LogsAnomaly** es un sistema de detecciÃ³n de anomalÃ­as en logs que combina Machine Learning con IA local para identificar y explicar comportamientos sospechosos. El sistema estÃ¡ siendo optimizado para manejar archivos de logs masivos (35MB - 2GB).

---

## ğŸ—ï¸ Nueva Arquitectura Multi-DB

### **Stack TecnolÃ³gico Actualizado**
- **Backend**: FastAPI (Python 3.11)
- **Frontend**: Vue 3 + TypeScript + PrimeVue
- **IA/ML**: Ollama + Nidum-Gemma-2B-Uncensored-GGUF
- **Bases de Datos**:
  - MongoDB (logs masivos)
  - PostgreSQL (metadatos)
  - Redis (cache y colas)
- **ContainerizaciÃ³n**: Docker + Docker Compose
- **Proxy**: Nginx

### **Arquitectura de Base de Datos**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MongoDB      â”‚    â”‚   PostgreSQL    â”‚    â”‚     Redis       â”‚
â”‚  (Logs Raw)     â”‚    â”‚  (Metadatos)    â”‚    â”‚(Cache y Colas)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Anomaly Detectorâ”‚
                    â”‚   (FastAPI)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flujo de Procesamiento Optimizado

### **1. Ingesta de Datos**
- Archivos de hasta 2GB
- DivisiÃ³n en chunks de 1MB
- Almacenamiento en MongoDB
- Tracking en PostgreSQL

### **2. Procesamiento Paralelo**
- 4-8 workers simultÃ¡neos
- Cola de procesamiento en Redis
- Cache de patrones comunes
- Resultados incrementales

### **3. Almacenamiento**
- **MongoDB**: Logs raw y chunks
- **PostgreSQL**: Metadatos y control
- **Redis**: Cache y estado

---

## ğŸ“ Estructura de Datos Optimizada

### **MongoDB**
```javascript
// ColecciÃ³n: chunks
{
  "_id": ObjectId,
  "file_id": "uuid",
  "chunk_number": 1,
  "data": "contenido del chunk",
  "size": 1048576,  // 1MB
  "processed": false,
  "created_at": ISODate
}

// ColecciÃ³n: results
{
  "_id": ObjectId,
  "chunk_id": ObjectId,
  "anomalies": [{
    "log_entry": "texto del log",
    "score": -0.15,
    "explanation": "explicaciÃ³n"
  }],
  "processing_time": 123,
  "created_at": ISODate
}
```

### **PostgreSQL**
```sql
-- Tabla: processing_jobs
CREATE TABLE processing_jobs (
    id UUID PRIMARY KEY,
    filename VARCHAR(255),
    total_size BIGINT,
    total_chunks INTEGER,
    chunks_processed INTEGER,
    status VARCHAR(50),
    started_at TIMESTAMP,
    completed_at TIMESTAMP
);

-- Tabla: processing_stats
CREATE TABLE processing_stats (
    id UUID PRIMARY KEY,
    job_id UUID,
    chunk_number INTEGER,
    processing_time FLOAT,
    anomalies_found INTEGER,
    created_at TIMESTAMP
);
```

### **Redis**
```redis
# Colas y Cache
processing:job:{id}:status -> hash
processing:job:{id}:progress -> string
queue:chunks_to_process -> list
cache:pattern:{hash} -> string
```

---

## ğŸ³ ConfiguraciÃ³n Docker Optimizada

### **Docker Compose**
```yaml
services:
  mongodb:
    image: mongo:7.0
    volumes:
      - mongodb_data:/data/db
    
  postgres:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data
    
  redis:
    image: redis:7
    volumes:
      - redis_data:/data

  anomaly-detector:
    build: ./
    depends_on:
      - mongodb
      - postgres
      - redis
```

---

## ğŸ“Š MÃ©tricas y Rendimiento

### **Capacidades de Procesamiento**
- **Archivos**: Hasta 2GB
- **Chunks**: 1MB por chunk
- **Workers**: 4-8 paralelos
- **Memoria**: 16GB recomendado

### **Tiempos Esperados**
- **500MB**: ~5 minutos
- **1GB**: ~10 minutos
- **2GB**: ~20-30 minutos

---

## ğŸ”§ Configuraciones

### **MongoDB**
```javascript
// Ãndices optimizados
db.chunks.createIndex({"file_id": 1, "chunk_number": 1})
db.chunks.createIndex({"processed": 1})
db.results.createIndex({"chunk_id": 1})
```

### **PostgreSQL**
```sql
-- Ãndices para consultas frecuentes
CREATE INDEX idx_jobs_status ON processing_jobs(status);
CREATE INDEX idx_jobs_filename ON processing_jobs(filename);
CREATE INDEX idx_stats_job_id ON processing_stats(job_id);
```

### **Redis**
```redis
# ConfiguraciÃ³n de persistencia
save 900 1
save 300 10
save 60 10000
maxmemory 8gb
maxmemory-policy allkeys-lru
```

---

## ğŸ¯ Estado de ImplementaciÃ³n

### âœ… **Completado**
- Arquitectura base
- Procesamiento bÃ¡sico
- UI inicial

### ğŸ”„ **En Progreso**
- MigraciÃ³n a Multi-DB
- Sistema de chunks
- Procesamiento paralelo

### ğŸ“‹ **Pendiente**
- OptimizaciÃ³n de Ã­ndices
- Fine-tuning de workers
- Dashboard de monitoreo

---

## ğŸš€ PrÃ³ximos Pasos

1. **Implementar MongoDB** para logs masivos
2. **Configurar PostgreSQL** para metadatos
3. **Integrar Redis** para cache
4. **Optimizar procesamiento** paralelo
5. **Mejorar UI** para archivos grandes

---

**Ãšltima actualizaciÃ³n**: 11 de enero de 2025  
**VersiÃ³n**: 1.1.0  
**Estado**: En optimizaciÃ³n para archivos masivos